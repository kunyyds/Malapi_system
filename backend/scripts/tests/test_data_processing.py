#!/usr/bin/env python3
"""
æ•°æ®å¤„ç†å±‚æµ‹è¯•è„šæœ¬

è®¾è®¡æ€è·¯ï¼š
1. æµ‹è¯•æ–‡ä»¶æ‰«æã€è§£æã€å¯¼å…¥çš„å®Œæ•´æµç¨‹
2. éªŒè¯æ•™å­¦çº§æ³¨é‡Šä»£ç çš„åŠŸèƒ½
3. æä¾›è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Šå’Œæ€§èƒ½åˆ†æ
4. ç¡®ä¿ç³»ç»Ÿåœ¨çœŸå®æ•°æ®ä¸Šçš„è¡¨ç°

ä½¿ç”¨æ–¹æ³•ï¼š
python test_data_processing.py
"""

import asyncio
import logging
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('test_data_processing.log')
    ]
)

logger = logging.getLogger(__name__)


async def test_file_scanner():
    """æµ‹è¯•æ–‡ä»¶æ‰«æå™¨"""
    logger.info("=" * 50)
    logger.info("æµ‹è¯•æ–‡ä»¶æ‰«æå™¨")
    logger.info("=" * 50)

    from src.parsers.file_scanner import FileScanner

    # åˆ›å»ºæ‰«æå™¨
    scanner = FileScanner(max_workers=4, max_depth=10)

    # æ™ºèƒ½æ£€æµ‹æµ‹è¯•ç›®å½•è·¯å¾„
    files_directory = None
    possible_paths = [
        project_root.parent / "files",  # é»˜è®¤ä½ç½®
        project_root / "files",        # å½“å‰é¡¹ç›®ç›®å½•ä¸‹
        Path("/home/mine/workspace/MalAPI_system/files"),  # ç»å¯¹è·¯å¾„
    ]

    for path in possible_paths:
        if path.exists() and path.is_dir():
            files_directory = path
            logger.info(f"æ‰¾åˆ°æµ‹è¯•æ•°æ®ç›®å½•: {files_directory}")
            break

    if not files_directory:
        logger.error(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®ç›®å½•ï¼Œå°è¯•äº†ä»¥ä¸‹è·¯å¾„:")
        for path in possible_paths:
            logger.error(f"  - {path}")
        logger.error("è¯·ç¡®ä¿ files ç›®å½•å­˜åœ¨ä¸”åŒ…å« manifest.json æ–‡ä»¶")
        return None

    try:
        # æ‰«æmanifest.jsonæ–‡ä»¶
        logger.info(f"æ‰«æç›®å½•: {files_directory}")
        scan_result = await scanner.scan_directory(
            root_path=files_directory,
            pattern="manifest",
            recursive=True
        )

        # è¾“å‡ºæ‰«æç»“æœ
        logger.info(f"æ‰«æç»“æœ: {scan_result.get_summary()}")
        logger.info(f"æ‰¾åˆ°æ–‡ä»¶æ•°: {scan_result.get_file_count()}")

        # æ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶è·¯å¾„
        if scan_result.files:
            logger.info("å‰10ä¸ªæ–‡ä»¶:")
            for i, file_path in enumerate(scan_result.files[:10]):
                logger.info(f"  {i+1}. {file_path}")

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        scanner.print_statistics()

        return scan_result

    except Exception as e:
        logger.error(f"æ–‡ä»¶æ‰«æå™¨æµ‹è¯•å¤±è´¥: {e}")
        return None


async def test_manifest_parser(scan_result):
    """æµ‹è¯•manifestè§£æå™¨"""
    logger.info("=" * 50)
    logger.info("æµ‹è¯•manifestè§£æå™¨")
    logger.info("=" * 50)

    if not scan_result or not scan_result.files:
        logger.warning("æ²¡æœ‰æ–‡ä»¶å¯ä¾›æµ‹è¯•è§£æå™¨")
        return []

    from src.parsers.manifest_parser import ManifestParser

    # åˆ›å»ºè§£æå™¨
    parser = ManifestParser(strict_mode=False, validate_attack_ids=True)

    parse_results = []
    test_files = scan_result.files[:15]  # æµ‹è¯•å‰15ä¸ªæ–‡ä»¶

    try:
        logger.info(f"æµ‹è¯•è§£æ {len(test_files)} ä¸ªæ–‡ä»¶")

        for i, file_path in enumerate(test_files):
            logger.info(f"è§£ææ–‡ä»¶ {i+1}/{len(test_files)}: {file_path.name}")

            try:
                parse_result = await parser.parse_file(file_path)

                if parse_result.is_valid:
                    logger.info(f"  âœ… è§£ææˆåŠŸ: {parse_result.data.get('alias', 'N/A')}")
                    logger.info(f"     ATT&CKæŠ€æœ¯: {parse_result.data.get('attck', [])}")
                else:
                    logger.warning(f"  âŒ è§£æå¤±è´¥: {parse_result.get_error_summary()}")

                parse_results.append(parse_result)

            except Exception as e:
                logger.error(f"  âŒ è§£æå¼‚å¸¸: {e}")

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        parser_stats = parser.get_statistics()
        logger.info(f"è§£æç»Ÿè®¡: æˆåŠŸç‡ {parser_stats.get('success_rate', 0):.1f}%")
        logger.info(f"å¹³å‡é”™è¯¯æ•°: {parser_stats.get('average_errors_per_file', 0):.1f}")

        return parse_results

    except Exception as e:
        logger.error(f"manifestè§£æå™¨æµ‹è¯•å¤±è´¥: {e}")
        return []


async def test_database_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    logger.info("=" * 50)
    logger.info("æµ‹è¯•æ•°æ®åº“è¿æ¥")
    logger.info("=" * 50)

    try:
        from src.database.connection import async_engine, AsyncSessionLocal

        # æµ‹è¯•æ•°æ®åº“è¿æ¥
        async with AsyncSessionLocal() as session:
            # æ‰§è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•è¿æ¥
            from sqlalchemy import text
            result = await session.execute(text("SELECT 1"))
            logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")

            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ - æ”¯æŒå¤šç§æ•°æ®åº“ç±»å‹
            from src.database.models import MalAPIFunction
            from src.database.connection import async_engine

            # æ£€æµ‹æ•°æ®åº“ç±»å‹
            db_url = str(async_engine.url).lower()
            if 'sqlite' in db_url:
                # SQLite æŸ¥è¯¢
                result = await session.execute(text("SELECT name FROM sqlite_master WHERE type='table' AND name='malapi_functions'"))
            elif 'postgresql' in db_url:
                # PostgreSQL æŸ¥è¯¢
                result = await session.execute(text("SELECT tablename FROM pg_catalog.pg_tables WHERE tablename = 'malapi_functions'"))
            else:
                # é€šç”¨æŸ¥è¯¢ - å°è¯•ç›´æ¥æŸ¥è¯¢è¡¨
                try:
                    result = await session.execute(text("SELECT COUNT(*) FROM malapi_functions LIMIT 1"))
                    table_exists = True
                except Exception:
                    table_exists = False
                logger.info(f"æ•°æ®åº“ç±»å‹æ£€æµ‹: {db_url}")

            if 'sqlite' in db_url or 'postgresql' in db_url:
                table_exists = result.fetchone() is not None

            if table_exists:
                logger.info("âœ… æ•°æ®åº“è¡¨å·²åˆ›å»º")
            else:
                logger.info("ğŸ”§ æ•°æ®åº“è¡¨æœªåˆ›å»ºï¼Œæ­£åœ¨åˆå§‹åŒ–...")
                from src.database.connection import init_db
                await init_db()
                logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

        return True

    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        logger.error("è¯·æ£€æŸ¥ä»¥ä¸‹é…ç½®:")
        logger.error("  1. æ•°æ®åº“æœåŠ¡æ˜¯å¦è¿è¡Œ")
        logger.error("  2. .env æ–‡ä»¶ä¸­çš„æ•°æ®åº“é…ç½®æ˜¯å¦æ­£ç¡®")
        logger.error("  3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        return False


async def test_full_import_workflow():
    """æµ‹è¯•å®Œæ•´çš„å¯¼å…¥å·¥ä½œæµç¨‹"""
    logger.info("=" * 50)
    logger.info("æµ‹è¯•å®Œæ•´å¯¼å…¥å·¥ä½œæµç¨‹")
    logger.info("=" * 50)

    try:
        from src.database.connection import AsyncSessionLocal
        from src.importers.import_manager import ImportManager

        # åˆ›å»ºå¯¼å…¥ç®¡ç†å™¨
        session_factory = AsyncSessionLocal
        manager = ImportManager(session_factory)

        # è®¾ç½®è¿›åº¦å›è°ƒ
        def progress_callback(current, total, message):
            percentage = (current / total) * 100
            logger.info(f"è¿›åº¦: {percentage:.1f}% - {message}")

        manager.set_progress_callback(progress_callback)

        # æ™ºèƒ½æ£€æµ‹æµ‹è¯•ç›®å½•è·¯å¾„ï¼ˆå¤ç”¨å‰é¢çš„é€»è¾‘ï¼‰
        files_directory = None
        possible_paths = [
            project_root.parent / "files",  # é»˜è®¤ä½ç½®
            project_root / "files",        # å½“å‰é¡¹ç›®ç›®å½•ä¸‹
            Path("/home/mine/workspace/MalAPI_system/files"),  # ç»å¯¹è·¯å¾„
        ]

        for path in possible_paths:
            if path.exists() and path.is_dir():
                files_directory = path
                logger.info(f"ä½¿ç”¨æµ‹è¯•æ•°æ®ç›®å½•: {files_directory}")
                break

        if not files_directory:
            logger.error(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®ç›®å½•ï¼Œå¯¼å…¥æµç¨‹æµ‹è¯•å–æ¶ˆ")
            return None

        # æ‰§è¡Œå¯¼å…¥æµç¨‹ï¼ˆä»…æµ‹è¯•å°‘é‡æ–‡ä»¶ä»¥èŠ‚çœæ—¶é—´ï¼‰
        logger.info("å¼€å§‹å®Œæ•´å¯¼å…¥æµç¨‹æµ‹è¯•...")
        result = await manager.import_from_directory(
            directory_path=files_directory,
            pattern="manifest",
            recursive=True
        )

        # è¾“å‡ºç»“æœ
        logger.info(f"å¯¼å…¥æµç¨‹å®Œæˆ: {result.get_overall_summary()}")

        # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
        stats = result.get_stage_statistics()
        logger.info("è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:")
        for stage, stage_stats in stats.items():
            if isinstance(stage_stats, dict):
                logger.info(f"  {stage}:")
                for key, value in stage_stats.items():
                    logger.info(f"    {key}: {value}")

        # æ‰“å°ç®¡ç†å™¨ç»Ÿè®¡
        manager.print_statistics()

        return result

    except Exception as e:
        logger.error(f"âŒ å®Œæ•´å¯¼å…¥æµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return None


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    test_start_time = datetime.now()
    logger.info("ğŸš€ å¼€å§‹æ•°æ®å¤„ç†å±‚æµ‹è¯•")
    logger.info(f"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {test_start_time}")
    logger.info(f"ğŸ“‚ é¡¹ç›®è·¯å¾„: {project_root}")

    # æµ‹è¯•ç¯å¢ƒä¿¡æ¯
    logger.info("=" * 50)
    logger.info("æµ‹è¯•ç¯å¢ƒä¿¡æ¯")
    logger.info("=" * 50)
    logger.info(f"Pythonç‰ˆæœ¬: {sys.version}")
    logger.info(f"å·¥ä½œç›®å½•: {Path.cwd()}")

    # æ£€æŸ¥å…³é”®ä¾èµ–
    try:
        import sqlalchemy
        logger.info(f"SQLAlchemyç‰ˆæœ¬: {sqlalchemy.__version__}")
    except ImportError:
        logger.warning("SQLAlchemy æœªå®‰è£…")

    try:
        from src.parsers.manifest_parser import ManifestParser
        from src.parsers.file_scanner import FileScanner
        from src.importers.import_manager import ImportManager
        logger.info("âœ… æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return

    try:
        # æµ‹è¯•1: æ–‡ä»¶æ‰«æå™¨
        scan_result = await test_file_scanner()

        # æµ‹è¯•2: manifestè§£æå™¨
        parse_results = await test_manifest_parser(scan_result)

        # æµ‹è¯•3: æ•°æ®åº“è¿æ¥
        db_connected = await test_database_connection()

        # æµ‹è¯•4: å®Œæ•´å¯¼å…¥æµç¨‹ï¼ˆä»…åœ¨æ•°æ®åº“è¿æ¥æˆåŠŸæ—¶æ‰§è¡Œï¼‰
        if db_connected and scan_result and scan_result.get_file_count() > 0:
            # é™åˆ¶æµ‹è¯•æ–‡ä»¶æ•°é‡ä»¥èŠ‚çœæ—¶é—´
            original_files = scan_result.files.copy()
            scan_result.files = original_files[:8]  # æµ‹è¯•å‰8ä¸ªæ–‡ä»¶ï¼ˆåˆç†æ•°é‡çš„å®Œæ•´æµ‹è¯•ï¼‰
            scan_result.files_found = 8

            import_result = await test_full_import_workflow()

            # æ¢å¤åŸå§‹æ–‡ä»¶åˆ—è¡¨ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
            scan_result.files = original_files
            scan_result.files_found = len(original_files)
        else:
            logger.warning("è·³è¿‡å®Œæ•´å¯¼å…¥æµç¨‹æµ‹è¯•ï¼ˆæ•°æ®åº“è¿æ¥å¤±è´¥æˆ–æ²¡æœ‰æ–‡ä»¶ï¼‰")

        test_end_time = datetime.now()
        test_duration = test_end_time - test_start_time

        logger.info("=" * 50)
        logger.info("ğŸ‰ æ•°æ®å¤„ç†å±‚æµ‹è¯•å®Œæˆ")
        logger.info("=" * 50)
        logger.info(f"â° æµ‹è¯•ç»“æŸæ—¶é—´: {test_end_time}")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {test_duration.total_seconds():.2f} ç§’")

        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        logger.info("æµ‹è¯•æ€»ç»“:")
        logger.info(f"  æ–‡ä»¶æ‰«æ: {'âœ… æˆåŠŸ' if scan_result else 'âŒ å¤±è´¥'}")
        if scan_result:
            logger.info(f"    æ‰¾åˆ°æ–‡ä»¶æ•°: {scan_result.get_file_count()}")
        logger.info(f"  manifestè§£æ: {'âœ… æˆåŠŸ' if parse_results else 'âŒ å¤±è´¥'}")
        if parse_results:
            successful_parses = sum(1 for r in parse_results if r.is_valid)
            logger.info(f"    è§£ææˆåŠŸæ•°: {successful_parses}/{len(parse_results)}")
        logger.info(f"  æ•°æ®åº“è¿æ¥: {'âœ… æˆåŠŸ' if db_connected else 'âŒ å¤±è´¥'}")
        logger.info("=" * 50)

    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.error("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤åé‡æ–°è¿è¡Œæµ‹è¯•")


if __name__ == "__main__":
    print("ğŸš€ MalAPIæ•°æ®å¤„ç†å±‚æµ‹è¯•")
    print("ğŸ“‹ æµ‹è¯•å†…å®¹: æ–‡ä»¶æ‰«æå™¨ -> manifestè§£æå™¨ -> æ•°æ®åº“è¿æ¥ -> å®Œæ•´å¯¼å…¥æµç¨‹")
    print("ğŸ“ æµ‹è¯•æ—¥å¿—å°†ä¿å­˜åˆ° test_data_processing.log")
    print("=" * 60)

    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    asyncio.run(main())